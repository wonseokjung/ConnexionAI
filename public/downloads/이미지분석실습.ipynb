{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Hugging Face 이미지 분류 노트북\n",
        "\n",
        "이 노트북에서는 Hugging Face의 `transformers` 라이브러리에서 제공하는 이미지 분류 모델을 활용하여 이미지를 분석합니다.\n",
        "\n",
        "**순서:**\n",
        "1. **필요한 라이브러리 설치:**  \n",
        "   - `transformers`: 이미지 분류 모델 사용  \n",
        "   - `Pillow`: 이미지를 불러와 처리\n",
        "\n",
        "2. **이미지 분류 함수 정의:**  \n",
        "   - 지정된 이미지 파일을 열고, 분류 모델에 입력하여 예측 결과(라벨과 점수)를 반환합니다.\n",
        "\n",
        "3. **이미지 분석 실행:**  \n",
        "   - Colab에 업로드한 이미지 파일 경로를 지정하고, 함수를 실행하여 분석 결과를 출력합니다.\n",
        "\n",
        "이제 아래 코드 셀들을 순서대로 실행해 보세요!\n"
      ],
      "metadata": {
        "id": "fHlIJE_zXCsn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "코드 셀 1: 라이브러리 설치 및 임포트\n"
      ],
      "metadata": {
        "id": "wiODULZ8XMiR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers pillow\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pa4iZ85lXJLR",
        "outputId": "bfb138f5-41f3-4206-97ab-6090e268a818"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.48.3)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (11.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.17.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.28.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "코드 셀 2: 이미지 분류 모델 준비 및 함수 정의\n",
        "\n"
      ],
      "metadata": {
        "id": "koOrnB-JXKCo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "from PIL import Image\n",
        "\n",
        "# Hugging Face의 이미지 분류 모델 준비\n",
        "classifier = pipeline(\"image-classification\")\n",
        "\n",
        "def analyze_image(image_path):\n",
        "    \"\"\"\n",
        "    주어진 이미지 파일 경로를 받아 이미지를 열고,\n",
        "    이미지 분류 모델을 통해 예측 결과를 반환합니다.\n",
        "\n",
        "    매개변수:\n",
        "      image_path (str): 분석할 이미지 파일 경로\n",
        "\n",
        "    반환값:\n",
        "      predictions (list): 예측 결과 리스트 (각 항목은 label과 score 포함)\n",
        "    \"\"\"\n",
        "    image = Image.open(image_path)  # 이미지 열기\n",
        "    predictions = classifier(image) # 모델로 예측 실행\n",
        "    return predictions\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oC2wiLX0jR5u",
        "outputId": "e831a127-cac3-4c57-f6af-a6638d2ae895"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to google/vit-base-patch16-224 and revision 3f49326 (https://huggingface.co/google/vit-base-patch16-224).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "Fast image processor class <class 'transformers.models.vit.image_processing_vit_fast.ViTImageProcessorFast'> is available for this model. Using slow image processor class. To use the fast image processor class set `use_fast=True`.\n",
            "Device set to use cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "코드 셀 3: 이미지 분석 실행"
      ],
      "metadata": {
        "id": "okbnkMuOjTRD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 예시: 이미지 파일 경로 설정 (Colab에 업로드한 파일명을 입력하세요)\n",
        "image_path = \"/content/DSC_0020.jpg\"  # 실제 파일명으로 변경 필요\n",
        "\n",
        "# 이미지 분석 함수 호출\n",
        "predictions = analyze_image(image_path)\n",
        "\n",
        "# 분석 결과 출력\n",
        "print(\"이미지 분류 결과:\")\n",
        "print(predictions)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1u2TvNT4jXSj",
        "outputId": "04690a4b-86bb-4f34-a2b3-53c259555049"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "이미지 분류 결과:\n",
            "[{'label': 'puck, hockey puck', 'score': 0.990995466709137}, {'label': 'broom', 'score': 0.0005391877493821084}, {'label': 'knee pad', 'score': 0.0005256811273284256}, {'label': 'football helmet', 'score': 0.00011621896555880085}, {'label': 'ski', 'score': 0.00011463767441455275}]\n"
          ]
        }
      ]
    }
  ]
}